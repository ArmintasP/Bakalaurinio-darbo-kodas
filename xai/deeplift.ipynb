{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f05878ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from captum.attr import DeepLift\n",
    "import warnings # for Deeplift supression.\n",
    "import time\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../utils\"))\n",
    "import myextensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17c8d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "\n",
    "model = myextensions.get_vgg()\n",
    "xai = DeepLift(model, multiply_by_inputs= True, eps= 1e-10)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"captum\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2708e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_3_heatmaps(dATASET_PATH, filename, attributions, input_image):\n",
    "    filepath_pos = os.path.join(dATASET_PATH, \"pos\", filename)\n",
    "    filepath_neg = os.path.join(dATASET_PATH, \"neg\", filename)\n",
    "    filepath_all = os.path.join(dATASET_PATH, \"all\", filename)\n",
    "    filepath_blended = os.path.join(dATASET_PATH, \"blended\", filename)\n",
    "\n",
    "    myextensions.save_result(attributions= attributions, image= input_image,\n",
    "                 save_path=filepath_pos, method=\"heat_map\", sign=\"positive\", outlier_perc=2)\n",
    "    \n",
    "    myextensions.save_result(attributions= attributions, image= input_image,\n",
    "                save_path=filepath_neg, method=\"heat_map\", sign=\"negative\", outlier_perc=2)\n",
    "    \n",
    "    myextensions.save_result(attributions= attributions, image= input_image,\n",
    "                save_path=filepath_all, method=\"heat_map\", sign=\"all\", outlier_perc=2)\n",
    "        \n",
    "    myextensions.save_result(attributions= attributions, image= input_image,\n",
    "                save_path=filepath_blended, method=\"blended_heat_map\", sign=\"all\", outlier_perc=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13a495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePaths = []\n",
    "timings = []\n",
    "\n",
    "MODES = \\\n",
    "[\n",
    "    \"adversial-patch/success\", \"adversial-patch/fail\",\n",
    "    \"feature-adversaries/success\", \"feature-adversaries/fail\",\n",
    "    \"fgsm/success\", \"fgsm/fail\",\n",
    "    \"no-attack\", \n",
    "    \"pgd/success\", \"pgd/fail\",\n",
    "    \"shadow-attack-nontargeted/success\", \"shadow-attack-nontargeted/fail\",\n",
    "    \"square-attack-l2/success\", \"square-attack-l2/fail\",\n",
    "    \"square-attack-linf/success\", \"square-attack-linf/fail\",\n",
    "]\n",
    "\n",
    "for mode in MODES:\n",
    "    dATASET_PATH = f\"../../inputs/{mode}\"\n",
    "\n",
    "    sAVE_DIR_PATH = f\"/home/cat/uni/bakis/outputs/deeplift/{mode}\"\n",
    "\n",
    "    Path(f\"{sAVE_DIR_PATH}/pos\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"{sAVE_DIR_PATH}/neg\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"{sAVE_DIR_PATH}/all\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"{sAVE_DIR_PATH}/blended\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    for filename in os.listdir(dATASET_PATH):\n",
    "        full_path = os.path.join(dATASET_PATH, filename)\n",
    "\n",
    "        input_image, _ = myextensions.get_image(full_path, myextensions.PREPROCESS_ATTACK)\n",
    "\n",
    "        pred_label_idx, predicted_label, prediction_score = myextensions.get_prediction(model, input_image)\n",
    "\n",
    "\n",
    "        input_image.requires_grad_()\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        attribution = xai.attribute(input_image, target= pred_label_idx)\n",
    "        elapsed = time.perf_counter() - start_time\n",
    "        timings.append(elapsed)\n",
    "\n",
    "        save_3_heatmaps(sAVE_DIR_PATH, filename, attribution, input_image)\n",
    "\n",
    "    if (timings != []):\n",
    "        timings_np = np.array(timings)\n",
    "        with open(f'{sAVE_DIR_PATH}/time_statistics.txt', \"w\") as f:\n",
    "            f.write(\"=== Attribution Time Stats ===\\n\")\n",
    "            f.write(f\"Total images:      {len(timings)}\\n\")\n",
    "            f.write(f\"Average time:      {timings_np.mean():.4f} s\\n\")\n",
    "            f.write(f\"Standard deviation:{timings_np.std():.4f} s\\n\")\n",
    "            f.write(f\"Minimum time:      {timings_np.min():.4f} s\\n\")\n",
    "            f.write(f\"Maximum time:      {timings_np.max():.4f} s\\n\")\n",
    "\n",
    "            f.write(f\"Epsilon (model parameter):      {xai.eps} s\\n\")\n",
    "        timings = []\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "captum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
